{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from utilities import pre_process_data\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor, HistGradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbose=0),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "    'ExtraTrees': ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "    'HistGradientBoosting': HistGradientBoostingRegressor(max_iter=100, learning_rate=0.1, max_leaf_nodes=31, max_depth=None, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiments and their specific important features\n",
    "experiments = [\n",
    "    {\n",
    "        'name': 'Auto Premium',\n",
    "        'module' : 'auto_insurance_premium',\n",
    "        'prefix': 'auto',\n",
    "        'important_features': {'Age', 'Gender', 'State', 'Business Use', 'Annual kilometers'}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Cyber Security',\n",
    "        'prefix': 'cyber',\n",
    "        'module' : 'cybersecurity_insurance_premium',\n",
    "        'important_features': {'Company Size', 'Industry Risk', 'Security Score', 'Data Sensitivity', \n",
    "                                       'Business Interruption Cost'}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Environment Liability',\n",
    "        'prefix': 'env_liab',\n",
    "        'module' : 'env_liability_insurance_premium',\n",
    "        'important_features': {'Industry Type', 'Company Size', 'Pollution Risk', \n",
    "                                       'Regulatory Compliance', 'Years of Operation', \n",
    "                                       'Incident History', 'Coverage Limit'}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Target Column\n",
    "target_column = 'Premium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "sample_sizes = [100,500,1000,5000]\n",
    "experiments_to_run = ['Auto Premium', 'Cyber Security', 'Environment Liability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135ffa6be4224051a6373834c367e8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Auto Premium:   0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d934e40f17dd41f98fd2ac4cb89d5f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd4f5ae75b04bb9baf061ac63728b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe1872d66de438faaa0e59bc2dac3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4ec399516b43268f42855ad1ec0112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e85db265c747f2addc620bdd9a3747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc5d9c1fa2649efac576350b48d1f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d669fba3a77449f9b2870df03865583a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main loop to iterate through experiments\n",
    "for experiment in experiments:\n",
    "    if experiment['name'] in experiments_to_run:\n",
    "        experiment_name = experiment['name']\n",
    "        experiment_module_name = experiment['module']\n",
    "        experiment_prefix = experiment['prefix']\n",
    "        important_features = experiment['important_features']\n",
    "\n",
    "        # Dynamically import the module containing the `generate_test_data` method\n",
    "        experiment_module = importlib.import_module(experiment_module_name)\n",
    "        generate_test_data = getattr(experiment_module, 'generate_test_data')\n",
    "\n",
    "        # Initialize dictionaries to collect results across multiple runs\n",
    "        overall_results = defaultdict(lambda: defaultdict(lambda: {'matches': 0, 'R²': [], 'MAE': [], 'RMSE': [], 'Accuracy': []}))\n",
    "\n",
    "        # Table to collect results per experiment\n",
    "        results_table = []\n",
    "        exp_index = 1\n",
    "\n",
    "        # Set up the progress bar for N * sample_sizes * models total iterations\n",
    "        total_iterations = N * len(sample_sizes) * len(models)\n",
    "        with tqdm(total=total_iterations, desc=f\"Running {experiment_name}\", position=0, leave=True) as pbar:\n",
    "            for iteration in range(N):\n",
    "                for size in sample_sizes:\n",
    "                    try:\n",
    "                        # Generate dataset using the experiment-specific method\n",
    "                        data = generate_test_data(size)\n",
    "\n",
    "                        X_processed, y, mappings = pre_process_data(data, target_column=target_column)\n",
    "\n",
    "                        # Split the data into training and test sets\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=7)\n",
    "\n",
    "                        # Evaluate each model\n",
    "                        for name, model in models.items():\n",
    "                            try:\n",
    "                                # Fit the model on the training data\n",
    "                                model.fit(X_train, y_train)\n",
    "\n",
    "                                # Evaluate the model on the test data\n",
    "                                y_pred = model.predict(X_test)\n",
    "\n",
    "                                # Calculate evaluation metrics\n",
    "                                r2_score = model.score(X_test, y_test)\n",
    "                                mse_score = mean_squared_error(y_test, y_pred)\n",
    "                                mae_score = mean_absolute_error(y_test, y_pred)\n",
    "                                rmse_score = np.sqrt(mse_score)\n",
    "                                accuracy_score = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "                                # SHAP analysis\n",
    "                                if isinstance(model, (RandomForestRegressor, GradientBoostingRegressor, XGBRegressor, CatBoostRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor)):\n",
    "                                    explainer = shap.TreeExplainer(model, feature_perturbation='interventional')\n",
    "                                    shap_values = explainer.shap_values(X_test, check_additivity=False)\n",
    "                                else:\n",
    "                                    # For non-tree based models, use KernelExplainer\n",
    "                                    explainer = shap.KernelExplainer(model.predict, shap.sample(X_train, 100))\n",
    "                                    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "                                # Calculate SHAP feature importance\n",
    "                                shap_feature_importance = dict(zip(X_processed.columns, np.mean(np.abs(shap_values), axis=0)))\n",
    "\n",
    "                                # Determine the top SHAP features\n",
    "                                sorted_features = sorted(shap_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "                                sorted_feature_names = [feature for feature, importance in sorted_features]\n",
    "                                top_features = set(sorted_feature_names[:len(important_features)])\n",
    "\n",
    "                                # Store the top features and their relevance\n",
    "                                top_shap_features = {feature: importance for feature, importance in sorted_features[:len(important_features)]}\n",
    "\n",
    "                                # Calculate the percentage of important features present in SHAP\n",
    "                                match_percentage = len(important_features.intersection(top_features)) / len(important_features) * 100.\n",
    "\n",
    "                                # Store all the results in a row\n",
    "                                results_table.append({\n",
    "                                    'Experiment Index': exp_index,\n",
    "                                    'Model': name,\n",
    "                                    'Sample Size': size,\n",
    "                                    'R²': r2_score,\n",
    "                                    'MAE': mae_score,\n",
    "                                    'RMSE': rmse_score,\n",
    "                                    'Accuracy': accuracy_score,\n",
    "                                    'SHAP Match Percentage': match_percentage,\n",
    "                                    'Top SHAP Features': top_shap_features\n",
    "                                })\n",
    "\n",
    "                                exp_index += 1\n",
    "                                # Update the progress bar\n",
    "                                pbar.update(1)\n",
    "                                # Optionally, you can add a description to show current progress\n",
    "                                pbar.set_postfix(iteration=iteration+1, size=size, model=name)\n",
    "                            except Exception as e:\n",
    "                                tqdm.write(f\"Error with model {name} at sample size {size}: {e}\")\n",
    "                                # Still update the progress bar even if there's an error\n",
    "                                pbar.update(1)\n",
    "                                continue  # Skip to the next model\n",
    "\n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f\"Error during processing at sample size {size}: {e}\")\n",
    "                        # Update the progress bar for all models in this failed iteration\n",
    "                        pbar.update(len(models))\n",
    "                        continue  # Skip to the next sample size\n",
    "\n",
    "        # Convert results table to DataFrame for better analysis\n",
    "        raw_results_df = pd.DataFrame(results_table)\n",
    "\n",
    "        # Save the raw results for this experiment to a CSV file\n",
    "        csv_filename = f\"exp2_results_{experiment_prefix}.csv\"\n",
    "        raw_results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "        print(f\"\\nResults for {experiment_name} saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPIT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
